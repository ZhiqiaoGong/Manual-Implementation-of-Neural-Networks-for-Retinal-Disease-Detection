{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torch.utils.data import sampler\n",
    "from torchvision import models\n",
    "\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use GPU\n",
    "USE_GPU = True\n",
    "\n",
    "dtype = torch.float32\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize some training images\n",
    "data_dir = 'OCT2017/train'\n",
    "train_dir = 'data/train'\n",
    "val_dir = 'data/val'\n",
    "test_dir = 'data/test'\n",
    "class_names = ['CNV', 'DME', 'DRUSEN', 'NORMAL']\n",
    "\n",
    "num_images = 5\n",
    "\n",
    "fig, axes = plt.subplots(len(class_names), num_images, figsize=(num_images * 2, len(class_names) * 2))\n",
    "fig.suptitle('Sample Images from Each Class', fontsize=16)\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    class_dir = os.path.join(train_dir, class_name)\n",
    "    image_files = os.listdir(class_dir)[:num_images]\n",
    "    for j, image_file in enumerate(image_files):\n",
    "        image_path = os.path.join(class_dir, image_file)\n",
    "        image = Image.open(image_path)\n",
    "        ax = axes[i, j]\n",
    "        ax.imshow(image, cmap='gray')\n",
    "        ax.axis('off')\n",
    "        ax.set_title(class_name)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run only first time to split data\n",
    "# # Ensure the directories exist\n",
    "# os.makedirs(train_dir, exist_ok=True)\n",
    "# os.makedirs(val_dir, exist_ok=True)\n",
    "# os.makedirs(test_dir, exist_ok=True)\n",
    "#\n",
    "# # Create train, val, test folders for each class\n",
    "# for folder in ['CNV', 'DME', 'DRUSEN', 'NORMAL']:\n",
    "#     os.makedirs(os.path.join(train_dir, folder), exist_ok=True)\n",
    "#     os.makedirs(os.path.join(val_dir, folder), exist_ok=True)\n",
    "#     os.makedirs(os.path.join(test_dir, folder), exist_ok=True)\n",
    "#\n",
    "# # Split data into train, validation, and test sets\n",
    "# def split_data(source_dir, train_dir, val_dir, test_dir, split_ratio=(0.8, 0.1, 0.1)):\n",
    "#     for category in os.listdir(source_dir):\n",
    "#         category_path = os.path.join(source_dir, category)\n",
    "#         if os.path.isdir(category_path):\n",
    "#             files = os.listdir(category_path)\n",
    "#\n",
    "#             train_files, test_files = train_test_split(files, test_size=0.1, random_state=42)\n",
    "#             train_files, val_files = train_test_split(train_files, test_size=0.1 / 0.9, random_state=42)\n",
    "#\n",
    "#             for file in train_files:\n",
    "#                 shutil.move(os.path.join(category_path, file), os.path.join(train_dir, category, file))\n",
    "#\n",
    "#             for file in val_files:\n",
    "#                 shutil.move(os.path.join(category_path, file), os.path.join(val_dir, category, file))\n",
    "#\n",
    "#             for file in test_files:\n",
    "#                 shutil.move(os.path.join(category_path, file), os.path.join(test_dir, category, file))\n",
    "#\n",
    "# # Call the function to split the data\n",
    "# split_data(data_dir, train_dir, val_dir, test_dir)\n",
    "#\n",
    "# train_transforms = transforms.Compose([\n",
    "#     transforms.RandomResizedCrop(224),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.ToTensor(),\n",
    "#     #     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "# ])\n",
    "#\n",
    "# val_test_transforms = transforms.Compose([\n",
    "#     transforms.Resize(256),\n",
    "#     transforms.CenterCrop(224),\n",
    "#     transforms.ToTensor(),\n",
    "#     #     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "# ])\n",
    "#\n",
    "# batch_size = 32\n",
    "#\n",
    "# # Load datasets with ImageFolder\n",
    "# train_dataset = datasets.ImageFolder(train_dir, transform=train_transforms)\n",
    "# val_dataset = datasets.ImageFolder(val_dir, transform=val_test_transforms)\n",
    "# test_dataset = datasets.ImageFolder(test_dir, transform=val_test_transforms)\n",
    "#\n",
    "# # Create data loaders\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "#\n",
    "# # Get dataset sizes\n",
    "# train_size = len(train_dataset)\n",
    "# val_size = len(val_dataset)\n",
    "# test_size = len(test_dataset)\n",
    "#\n",
    "# # Get class names\n",
    "# class_names = train_dataset.classes\n",
    "#\n",
    "# print(f\"Classes: {class_names}\")\n",
    "# print(f\"Train dataset size: {train_size}\")\n",
    "# print(f\"Validation dataset size: {val_size}\")\n",
    "# print(f\"Test dataset size: {test_size}\")\n",
    "#\n",
    "# # Example of using the data loader to get a batch of training data\n",
    "# example_batch = next(iter(train_loader))\n",
    "# images, labels = example_batch\n",
    "# print(f\"Batch of images shape: {images.shape}\")\n",
    "# print(f\"Batch of labels: {labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    #     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_test_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    #     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Load datasets with ImageFolder\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=train_transforms)\n",
    "val_dataset = datasets.ImageFolder(val_dir, transform=val_test_transforms)\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=val_test_transforms)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "# Get dataset sizes\n",
    "train_size = len(train_dataset)\n",
    "val_size = len(val_dataset)\n",
    "test_size = len(test_dataset)\n",
    "\n",
    "# Get class names\n",
    "class_names = train_dataset.classes\n",
    "\n",
    "print(f\"Classes: {class_names}\")\n",
    "print(f\"Train dataset size: {train_size}\")\n",
    "print(f\"Validation dataset size: {val_size}\")\n",
    "print(f\"Test dataset size: {test_size}\")\n",
    "\n",
    "# Example of using the data loader to get a batch of training data\n",
    "example_batch = next(iter(train_loader))\n",
    "images, labels = example_batch\n",
    "print(f\"Batch of images shape: {images.shape}\")\n",
    "print(f\"Batch of labels: {labels}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images after preprocessing\n",
    "index_to_class = {\n",
    "    0: 'CNV',\n",
    "    1: 'DME',\n",
    "    2: 'DRUSSEN',\n",
    "    3: 'NORMAL'\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(4, 5, figsize=(5 * 2, 4 * 2))\n",
    "fig.suptitle('Sample Images after Preprocessing', fontsize=16)\n",
    "\n",
    "for i in range(4):\n",
    "    for j in range(5):\n",
    "        image = images[i * 4 + j]\n",
    "        image = np.transpose(image, (1, 2, 0))\n",
    "        ax = axes[i, j]\n",
    "        ax.imshow(image, cmap='gray')\n",
    "        ax.axis('off')\n",
    "        ax.set_title(index_to_class.get(int(labels[i * 4 + j])))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility funcs\n",
    "def flatten(x):\n",
    "    N = x.shape[0] # read in N, C, H, W\n",
    "    return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image\n",
    "\n",
    "def check_accuracy(loader, model):\n",
    "    if loader == train_loader:\n",
    "        print('Checking accuracy on training set')\n",
    "    elif loader == val_loader:\n",
    "        print('Checking accuracy on validation set')\n",
    "    else:\n",
    "        print('Checking accuracy on test set')\n",
    "\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
    "        return 100 * acc\n",
    "\n",
    "def train(model, optimizer, epochs=1):\n",
    "    model = model.to(device=device)\n",
    "    acc_max = 0\n",
    "    for e in range(epochs):\n",
    "        train_loss, correct = 0, 0\n",
    "        for t, (x, y) in enumerate(train_loader):\n",
    "\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "            train_loss += loss.item()\n",
    "            correct += (scores.argmax(1) == y).sum()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "        average_train_loss = train_loss / len(train_loader)\n",
    "        accuracy = correct / len(train_loader.dataset)\n",
    "        print('Epoch %d, loss = %.4f, acc = %.4f' % (e, average_train_loss, accuracy))\n",
    "        check_accuracy(val_loader, model)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train with print time\n",
    "import time  # Import the time module\n",
    "\n",
    "def train(model, optimizer, epochs=1):\n",
    "    model = model.to(device=device)\n",
    "    acc_max = 0\n",
    "    total_time = 0  # Initialize total time for averaging later\n",
    "\n",
    "    for e in range(epochs):\n",
    "        train_loss, correct = 0, 0\n",
    "        start_time = time.time()  # Record the start time of the epoch\n",
    "\n",
    "        for t, (x, y) in enumerate(train_loader):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "            train_loss += loss.item()\n",
    "            correct += (scores.argmax(1) == y).sum()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        end_time = time.time()  # Record the end time of the epoch\n",
    "        epoch_duration = end_time - start_time  # Calculate the duration of the epoch\n",
    "        total_time += epoch_duration  # Accumulate the total time\n",
    "\n",
    "        average_train_loss = train_loss / len(train_loader)\n",
    "        accuracy = correct / len(train_loader.dataset)\n",
    "        print('Epoch %d, loss = %.4f, acc = %.4f, duration = %.2f seconds' % (e, average_train_loss, accuracy, epoch_duration))\n",
    "        check_accuracy(val_loader, model)\n",
    "        print()\n",
    "\n",
    "    average_epoch_time = total_time / epochs  # Calculate the average time per epoch\n",
    "    print('Average training time per epoch: %.2f seconds' % average_epoch_time)\n",
    "\n",
    "# Make sure the device and dtype are defined before calling this function\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dtype = torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, in_channel, channel_1, channel_2, num_classes):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channel, out_channels=channel_1, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=channel_1, out_channels=channel_2, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "        self.fc1 = nn.Linear(channel_2 * 56 * 56, num_classes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_every = 500\n",
    "\n",
    "channel_1 = 64\n",
    "channel_2 = 32\n",
    "learning_rate = 1e-3\n",
    "num_classes = len(train_dataset.classes)\n",
    "\n",
    "model = SimpleCNN(in_channel=3, channel_1=channel_1, channel_2=channel_2, num_classes=num_classes)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train(model, optimizer, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = model\n",
    "check_accuracy(test_loader, cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unet\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        self.down1 = self.conv_stage(in_channels, 64)\n",
    "        self.down2 = self.conv_stage(64, 128)\n",
    "        self.down3 = self.conv_stage(128, 256)\n",
    "        self.down4 = self.conv_stage(256, 512)\n",
    "\n",
    "        self.bottleneck = self.conv_stage(512, 1024)\n",
    "\n",
    "        self.up1 = self.up_conv_stage(1024, 512)\n",
    "        self.up2 = self.up_conv_stage(512, 256)\n",
    "        self.up3 = self.up_conv_stage(256, 128)\n",
    "        self.up4 = self.up_conv_stage(128, 64)\n",
    "\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Linear(64, num_classes)\n",
    "\n",
    "    def conv_stage(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "    def up_conv_stage(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        d1 = self.down1(x)\n",
    "        d2 = self.down2(d1)\n",
    "        d3 = self.down3(d2)\n",
    "        d4 = self.down4(d3)\n",
    "\n",
    "        bn = self.bottleneck(d4)\n",
    "\n",
    "        u1 = self.up1(bn)\n",
    "        u2 = self.up2(u1 + d4)  # Skip connection\n",
    "        u3 = self.up3(u2 + d3)\n",
    "        u4 = self.up4(u3 + d2)\n",
    "\n",
    "        pooled = self.global_avg_pool(u4 + d1)  # Final skip connection\n",
    "        flat = pooled.view(pooled.size(0), -1)\n",
    "        out = self.fc(flat)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_every = 500\n",
    "\n",
    "channel_1 = 64\n",
    "channel_2 = 32\n",
    "learning_rate = 1e-4\n",
    "num_classes = len(train_dataset.classes)\n",
    "\n",
    "model = UNet(in_channels=3, num_classes=num_classes)  # for CNV, DME, DRUSEN, NORMAL\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay = 1e-5)\n",
    "\n",
    "train(model, optimizer, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = model\n",
    "check_accuracy(test_loader, unet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unet with resnet pretrained weight\n",
    "class UNetResNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(UNetResNet, self).__init__()\n",
    "        resnet = models.resnet34(pretrained=True)\n",
    "        self.base_layers = list(resnet.children())  # all layers except the last fully connected layer\n",
    "\n",
    "        # Down path\n",
    "        self.enc1 = nn.Sequential(*self.base_layers[:3])  # size=(N, 64, x.H/2, x.W/2)\n",
    "        self.enc2 = nn.Sequential(*self.base_layers[3:5])  # size=(N, 64, x.H/4, x.W/4)\n",
    "        self.enc3 = self.base_layers[5]  # size=(N, 128, x.H/8, x.W/8)\n",
    "        self.enc4 = self.base_layers[6]  # size=(N, 256, x.H/16, x.W/16)\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottleneck = self.base_layers[7]  # size=(N, 512, x.H/32, x.W/32)\n",
    "\n",
    "        # Up path\n",
    "        self.up4 = self.up_conv_stage(512, 256)\n",
    "        self.up3 = self.up_conv_stage(256, 128)\n",
    "        self.up2 = self.up_conv_stage(128, 64)\n",
    "        self.up1 = self.up_conv_stage(64, 64)\n",
    "\n",
    "        # Final output\n",
    "        self.final_conv = nn.Conv2d(64, num_classes, 1)  # num_classes output channels\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((1, 1))  # Pool to make spatial dimensions 1x1\n",
    "\n",
    "\n",
    "    def up_conv_stage(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder part\n",
    "        enc1 = self.enc1(x)\n",
    "        enc2 = self.enc2(enc1)\n",
    "        enc3 = self.enc3(enc2)\n",
    "        enc4 = self.enc4(enc3)\n",
    "\n",
    "        # Bottleneck\n",
    "        bottleneck = self.bottleneck(enc4)\n",
    "\n",
    "        # Decoder part\n",
    "        dec4 = self.up4(bottleneck) + enc4\n",
    "        dec3 = self.up3(dec4) + enc3\n",
    "        dec2 = self.up2(dec3) + enc2\n",
    "        dec1 = self.up1(dec2) + enc1\n",
    "\n",
    "        # Final output\n",
    "        out = self.final_conv(dec1)\n",
    "        out = self.adaptive_pool(out)  # Reduce to 1x1 spatially\n",
    "        out = torch.flatten(out, 1)  # Flatten the outputs into shape [N, num_classes]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_every = 500\n",
    "\n",
    "channel_1 = 64\n",
    "channel_2 = 32\n",
    "learning_rate = 1e-4\n",
    "model = UNetResNet(num_classes=4)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "\n",
    "train(model, optimizer, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_pretrained = model\n",
    "check_accuracy(test_loader, unet_pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# efficientnet\n",
    "class MBConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride, expand_ratio):\n",
    "        super(MBConv, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.stride = stride\n",
    "        self.expand_ratio = expand_ratio\n",
    "        hidden_dim = in_channels * expand_ratio\n",
    "\n",
    "        self.expansion = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, hidden_dim, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(hidden_dim),\n",
    "            nn.ReLU6(inplace=True)\n",
    "        ) if expand_ratio != 1 else nn.Identity()\n",
    "\n",
    "        self.depthwise = nn.Sequential(\n",
    "            nn.Conv2d(hidden_dim, hidden_dim, kernel_size=3, stride=stride, padding=1, groups=hidden_dim, bias=False),\n",
    "            nn.BatchNorm2d(hidden_dim),\n",
    "            nn.ReLU6(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Conv2d(hidden_dim, out_channels, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "\n",
    "        self.use_residual = self.stride == 1 and in_channels == out_channels\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        x = self.expansion(x)\n",
    "        x = self.depthwise(x)\n",
    "        x = self.projection(x)\n",
    "        if self.use_residual:\n",
    "            x = x + identity\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomEfficientNet(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(CustomEfficientNet, self).__init__()\n",
    "        self.initial_conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU6(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.mb_conv1 = MBConv(32, 16, stride=1, expand_ratio=1)\n",
    "        self.mb_conv2 = MBConv(16, 24, stride=2, expand_ratio=6)\n",
    "        self.mb_conv3 = MBConv(24, 40, stride=2, expand_ratio=6)\n",
    "        self.mb_conv4 = MBConv(40, 80, stride=2, expand_ratio=6)\n",
    "        self.mb_conv5 = MBConv(80, 112, stride=1, expand_ratio=6)\n",
    "        self.mb_conv6 = MBConv(112, 192, stride=2, expand_ratio=6)\n",
    "        self.mb_conv7 = MBConv(192, 320, stride=1, expand_ratio=6)\n",
    "\n",
    "        self.final_conv = nn.Sequential(\n",
    "            nn.Conv2d(320, 1280, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(1280),\n",
    "            nn.ReLU6(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.classifier = nn.Linear(1280, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.initial_conv(x)\n",
    "        x = self.mb_conv1(x)\n",
    "        x = self.mb_conv2(x)\n",
    "        x = self.mb_conv3(x)\n",
    "        x = self.mb_conv4(x)\n",
    "        x = self.mb_conv5(x)\n",
    "        x = self.mb_conv6(x)\n",
    "        x = self.mb_conv7(x)\n",
    "        x = self.final_conv(x)\n",
    "        x = self.global_pool(x)\n",
    "        x = torch.flatten(x, 1)  # Flatten the tensor\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_every = 500\n",
    "\n",
    "channel_1 = 64\n",
    "channel_2 = 32\n",
    "learning_rate = 1e-4\n",
    "num_classes = len(train_dataset.classes)\n",
    "\n",
    "model = CustomEfficientNet(num_classes=num_classes)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "\n",
    "train(model, optimizer, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficient = model\n",
    "check_accuracy(test_loader, efficient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# densenet\n",
    "class DenseLayer(nn.Module):\n",
    "    def __init__(self, in_channels, growth_rate):\n",
    "        super(DenseLayer, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "        self.conv1 = nn.Conv2d(in_channels, growth_rate, kernel_size=3, padding=1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(F.relu(self.bn1(x)))\n",
    "        out = torch.cat([x, out], 1)\n",
    "        return out\n",
    "\n",
    "class DenseBlock(nn.Module):\n",
    "    def __init__(self, in_channels, growth_rate, n_layers):\n",
    "        super(DenseBlock, self).__init__()\n",
    "        layers = []\n",
    "        for i in range(n_layers):\n",
    "            layers.append(DenseLayer(in_channels + i * growth_rate, growth_rate))\n",
    "        self.dense_block = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.dense_block(x)\n",
    "\n",
    "class TransitionLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(TransitionLayer, self).__init__()\n",
    "        self.bn = nn.BatchNorm2d(in_channels)\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self.pool = nn.AvgPool2d(2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(F.relu(self.bn(x)))\n",
    "        x = self.pool(x)\n",
    "        return x\n",
    "\n",
    "class DenseNet(nn.Module):\n",
    "    def __init__(self, num_classes=10, growth_rate=12, block_config=(6, 12, 24, 16), init_channels=24):\n",
    "        super(DenseNet, self).__init__()\n",
    "        self.growth_rate = growth_rate\n",
    "        self.init_channels = init_channels\n",
    "\n",
    "        # Initial convolution\n",
    "        self.conv1 = nn.Conv2d(3, init_channels, kernel_size=3, padding=1, bias=False)\n",
    "\n",
    "        # Dense blocks and transition layers\n",
    "        num_channels = init_channels\n",
    "        layers = []\n",
    "        for i, num_layers in enumerate(block_config):\n",
    "            layers.append(DenseBlock(num_channels, growth_rate, num_layers))\n",
    "            num_channels += num_layers * growth_rate\n",
    "            if i != len(block_config) - 1:\n",
    "                layers.append(TransitionLayer(num_channels, num_channels // 2))\n",
    "                num_channels = num_channels // 2\n",
    "        self.features = nn.Sequential(*layers)\n",
    "\n",
    "        # Classification layer\n",
    "        self.bn = nn.BatchNorm2d(num_channels)\n",
    "        self.fc = nn.Linear(num_channels, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.features(x)\n",
    "        x = F.relu(self.bn(x))\n",
    "        x = F.adaptive_avg_pool2d(x, (1, 1))\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_size = 50000  # the number of images in the subset\n",
    "dataset_size = len(train_dataset)\n",
    "indices = list(range(dataset_size))\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "subset_indices = indices[:subset_size]\n",
    "train_subset = Subset(train_dataset, subset_indices)\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_every = 200\n",
    "\n",
    "channel_1 = 64\n",
    "channel_2 = 32\n",
    "learning_rate = 1e-3\n",
    "num_classes = len(train_dataset.classes)\n",
    "\n",
    "model = DenseNet(num_classes=num_classes, growth_rate=12, block_config=(6, 12, 24, 16), init_channels=24)\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train(model, optimizer, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense = model\n",
    "check_accuracy(test_loader, dense)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
